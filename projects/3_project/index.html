<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Unlocking Speech Recognition for Spanish Dysarthric Speech | Margot Madina </title> <meta name="author" content="Margot Madina "> <meta name="description" content="A pilot study evaluating automatic Speech-To-Text (STT) for Spanish speakers with dysarthria"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://margotmg.github.io/projects/3_project/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Margot Madina</span> </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">case studies <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/assets/cv/cv.pdf">resume </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Unlocking Speech Recognition for Spanish Dysarthric Speech</h1> <p class="post-description">A pilot study evaluating automatic Speech-To-Text (STT) for Spanish speakers with dysarthria</p> </header> <article> <hr> <h2 id="overview">Overview</h2> <p><strong>Context</strong><br> Automatic Speech Recognition (ASR) systems have shown promise for users with speech impairments, offering potential accessibility benefits. However, dysarthric speech (resulting from neurological or physical conditions) poses significant recognition challenges. This pilot experiment examines how well the Microsoft Azure ASR system performs on Spanish dysarthric speech.</p> <p><strong>My Role</strong><br> Lead researcher: designing the pilot study, recruiting participants with dysarthric speech, running ASR evaluations, analyzing error types and performance metrics, and deriving design implications for assistive voice systems.</p> <p><strong>Timeline</strong><br> Approximately 10 months</p> <p><strong>Team &amp; Collaboration</strong><br> Worked with speech-technology researchers at ahoLAB (Basque Country), 3 people with dysarthric speech, and conducted human evaluations with 85 volunteers.</p> <hr> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/dysarthria-480.webp 480w,/assets/img/dysarthria-800.webp 800w,/assets/img/dysarthria-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/dysarthria.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> What is dysarthria? </div> <h2 id="-research-question">üéØ Research Question</h2> <blockquote> <p>How accurately do standard Spanish ASR systems recognize speech from users with dysarthria, and what error patterns or usability barriers emerge in this context?</p> </blockquote> <hr> <h2 id="methods">Methods</h2> <p><strong>Approach</strong></p> <ul> <li> <strong>Recruited participants</strong> with dysarthria and recorded scripted speech tasks under controlled conditions.</li> <li> <strong>Selected commercial STT solutions</strong> for Spanish and <strong>processed the speech recordings</strong> to obtain transcriptions.</li> <li> <strong>Measured recognition performance</strong> using metrics such as Word Error Rate (WER) and compared to baseline non-dysarthric data.</li> <li>Conducted <strong>qualitative error analysis</strong>: categorised mis-recognitions by phonetic difficulties, articulation, etc.</li> <li>Documented usability implications.</li> </ul> <h3 id="1-speech-data-collection">1. <strong>Speech Data Collection</strong> </h3> <ul> <li>Recruited participants and recorded them: <strong>3 native Spanish speakers</strong> with varying levels of dysarthria producing <strong>210 short voice commands</strong> each (21 different commands, 10 times each).</li> <li>Commands were chosen from text creation and edition programs.</li> <li>Participants recorded in their home environment, at different days and times to increase the variability of speech and mimic real-life scenarios.</li> </ul> <h3 id="2-automatic-stt-evaluation">2. <strong>Automatic STT Evaluation</strong> </h3> <ul> <li>Tested recordings with Microsoft Azure‚Äôs STT system and using different settings: with and without a finite grammar, and with and without training the baseline.</li> <li>Measured <strong>WER</strong> and error types (substitution, deletion, insertion).</li> <li>Conducted qualitative analysis of recurring error patterns linked to articulation and prosody differences.</li> </ul> <h3 id="3-live-speech-web-application">3. <strong>Live Speech Web Application</strong> </h3> <ul> <li>Developed a <strong>web interface</strong> enabling real-time speech input from dysarthric users.</li> <li>Allowed testing of <strong>live recognition</strong> scenarios instead of only pre-recorded audio.</li> <li>Observed recognition accuracy, and user experience of speaking directly to the system.</li> <li>Logged text outputs for later analysis and comparison with recorded benchmarks.</li> </ul> <h3 id="4-human-intelligibility-test">4. <strong>Human Intelligibility Test</strong> </h3> <ul> <li>Conducted a <strong>perceptual test</strong> with <strong>85 human listeners</strong>, each transcribing 30 randomly selected voice commands (10 per dysarthric participant).</li> <li>Goal: compare <strong>human comprehension</strong> to STT accuracy to see whether technology or human listeners perform better‚Äîand where intelligibility breaks down.</li> <li>Measured human transcription accuracy as a percentage of correct words and perceived difficulty.</li> </ul> <h3 id="5-participant-questionnaire">5. <strong>Participant Questionnaire</strong> </h3> <ul> <li>After all sessions, the three participants with dysarthria completed a short <strong>questionnaire</strong> about: <ul> <li>Ease/difficulty of recording and live-speech interaction</li> <li>Fatigue, frustration, and effort levels</li> <li>Their opinions about speech technologies and accessibility</li> </ul> </li> <li>Collected qualitative reflections on trust, usefulness, and emotional response to speech interfaces.</li> </ul> <p><strong>Why these methods?</strong><br> They combine quantitative performance metrics with qualitative error analysis and usability. This aligns with accessible-technology evaluation and real-user context.</p> <hr> <h2 id="key-findings--insights">Key Findings &amp; Insights</h2> <ul> <li> <strong>STT performance for dysarthric speech degraded significantly</strong> compared to typical speech.</li> <li> <strong>Human listeners</strong> still made comprehension errors, especially for moderate-to-severe dysarthric speech.</li> <li> <strong>Error patterns overlapped</strong> between human and machine transcription, suggesting shared difficulties with certain phonetic distortions. Strong connections were found between system errors, human comprehension ahcllenges, and each speaker‚Äôs specific pronunciation patterns.</li> <li> <strong>Cutomized models by the use of finite grammars</strong> improved the results significantly.</li> <li>The study highlights that <strong>commercial STT systems are not yet sufficient for dysarthric users</strong>, and specialised adaptation/training or user-specific models are needed.</li> <li>Participants‚Äô feedback highlighted both <strong>hope and frustration</strong>: they valued assistive potential but felt current systems fall short in recognizing their speeches.</li> </ul> <hr> <h2 id="design-recommendations--impact">Design Recommendations &amp; Impact</h2> <p><strong>Recommendations</strong></p> <ul> <li>Integrate <strong>user-specific adaptation</strong> or fine-tuning of STT models for dysarthric speakers to improve recognition.</li> <li>Build voice input systems with strong error-correction support: suggestions, confirmation, visual feedback, fallback input.</li> <li>Conduct <strong>co-design sessions with dysarthric users</strong> to understand their articulation patterns and how voice recognition errors affect communication workflows.</li> <li>Extend research with <strong>multi-speaker datasets</strong> and real-world interaction tasks (e.g., using speech in daily apps).</li> </ul> <p><strong>Impact</strong></p> <ul> <li>Created a dedicated <strong>speech database</strong> of Spanish dysarthric speech, containing 630 recorded voice commands, their transcriptions</li> <li>Provides <strong>empirical evidence of STT system limitations</strong> for Spanish dysarthric speech, supporting inclusive development.</li> <li>Helps product teams or researchers working on voice-input aids <strong>understand the performance gap</strong> and necessary features for improvement.</li> <li>Demonstrates capability to conduct applied <strong>accessibility research involving speech impairments, metrics, user contexts, and design implications</strong>.</li> </ul> <hr> <h2 id="reflections">Reflections</h2> <ul> <li>Working with participants with dysarthria underscored the importance of empathy, flexible test setups, and real-world context (not just lab speech).</li> <li>A <strong>mixed-methods approach</strong> (quantitative + qualitative) offered richer insight: numbers tell ‚Äúhow much worse‚Äù, taxonomy tells ‚Äúwhy worse‚Äù.</li> <li>The <strong>perceptual test</strong> validated that speech accessibility is not a binary ‚Äúworks/doesn‚Äôt work‚Äù issue, but a spectrum where even small clarity gains can drastically change usability.</li> <li>If repeating: I would include live assistive-scenario testing (e.g., voice-dictation tasks, communication device usage) rather than just scripted speech, to capture real-use usability.</li> <li>I gained stronger understanding of how speech impairments intersect with technology design and how to translate that into actionable system requirements.</li> </ul> <hr> <h2 id="outcome-statement">Outcome Statement</h2> <blockquote> <p>This pilot study exposes the gap between standard Spanish STT systems and the needs of users with dysarthria, offering a foundation for designing accessible voice-input workflows. I applied speech-technology metrics, error analysis, and user-context thinking to derive design recommendations, demonstrating how technical evaluation and inclusive design meet in assistive tools.</p> </blockquote> <hr> <p><a href="https://epub.jku.at/obvulioa/content/titleinfo/7945389/full.pdf" rel="external nofollow noopener" target="_blank">üìÑ Read the full paper here: Madina, M., Hern√°ez, I., &amp; Navas, E. (2022). Evaluation of STT Technology Performance for Spanish Dysarthric Speech: Description of a Pilot Experiment. ICCHP-AAATE 2022 Open Access Compendium‚Äù Assistive Technology, Accessibility and (e) Inclusion‚Äù Part I.</a></p> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> ¬© Copyright 2025 Margot Madina . </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> </body> </html>